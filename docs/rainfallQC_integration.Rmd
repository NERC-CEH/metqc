---
title: "rainfallQC_integration"
output: html_document
---

# GitHub package
Public repository for the rainfallQC is here: https://github.com/NERC-CEH/RainfallQC
There is a notebook demo of how the package works here: https://github.com/Thomasjkeel/RainfallQC-notebooks/blob/main/notebooks/demo/rainfallQC_demo.ipynb

# Dependencies 

Each machine will have to have a series of requirements: 
* phyton 3.8 or later
* Dependencies for the rainfallQC package ()
* R with shiny and dependencies for metqc app.

# How it will work with a shiny app: 

- Use the R reticulate package
- Create a function to automatically set up the Python environment
- when ready to use: 
```{gneral_example r}


library(reticulate)

# Import the Python module
rainfallqc <- import("rainfallqc")

# Call a specific function, say `your_function_name`
result <- rainfallqc$your_function_name(arg1, arg2)

```

# Working example with the app 

The rainfall variables is named as `P_12_1_1`. 
The python package needs datect to be separated as dates and hours. 

```{app_example r}
# The app reads in df_era5_qry that is the ate range met data, we want to filter P_12_1_1

df_prec <- df_era5_qry %>%
  dplyr::select(P_12_1_1, DATECT)

# rainfall needs to be in mm and date/time in the same column
# it seems to do a nearest neighbour comparison but not sure where to get that data? we only have from one location


library(reticulate)
# Import the Python module
rainfallqc <- import("rainfallqc")
py_help(rainfallqc$gauge_checks) # a module with several functions

py_help(rainfallqc$gauge_checks$check_years_where_annual_mean_k_top_rows_are_zero)

#####################
#prepare data for python
#####################
# the dataset needs to be a polars dataframe 
#py_install("polars")
pl <- import("polars")
# 2. Convert R data.frame to Python dict
df_dict <- dict(
  DATECT = as.character(df_prec$DATECT),
  P_12_1_1 = df_prec$P_12_1_1
)

# 3. Create a Polars DataFrame
pl_df <- pl$DataFrame(df_dict)

# 4. Convert DATECT to datetime format in Polars
pl_df <- pl_df$with_columns(
  pl$col("DATECT")$str$to_datetime()
)

# 5. Use group_by_dynamic to group by 30m intervals otherwise the rainfallqc package fails
grouped_df <- pl_df$group_by_dynamic("DATECT", every="30m")$agg(
  list(
   pl$col("P_12_1_1")$sum()$alias("P_12_1_1_sum")
  )
)
# rename DATECT to time so the rainfallqc package works
grouped_df <- grouped_df$rename(dict(DATECT = "time"))

#####################
#Gauge checks
#####################

rainfallqc$gauge_checks$check_years_where_annual_mean_k_top_rows_are_zero(
    grouped_df,
    "P_12_1_1_sum",
    k = 1800
)

rainfallqc$gauge_checks$check_years_where_nth_percentile_is_zero(grouped_df, "P_12_1_1_sum", quantile=0.8) # if return list() No years or groups matched the condition where the 80th percentile of P_12_1_1_sum was zero.

rainfallqc$gauge_checks$check_breakpoints(grouped_df, "P_12_1_1_sum")

rainfallqc$gauge_checks$check_intermittency(grouped_df, "P_12_1_1_sum")

rainfallqc$gauge_checks$check_min_val_change(grouped_df, "P_12_1_1_sum", expected_min_val=0.1)

rainfallqc$gauge_checks$check_temporal_bias(grouped_df, "P_12_1_1_sum", time_granularity="weekday")

#####################
#Comparison checks
#####################

# all the data in teh app so far is from the same site: 
# as example lets say lat 54.686534 , lng -2.1862793
#add lat lng to the existing data.frame
grouped_df$lat <- 54.686534
grouped_df$lng <- -2.1862793

rainfallqc$comparison_checks$check_annual_exceedance_etccdi_prcptot(
  grouped_df,
  "P_12_1_1_sum",
  gauge_lat = 54.686534,
  gauge_lon = -2.1862793
)

rainfallqc$comparison_checks$check_annual_exceedance_etccdi_r99p(
   grouped_df,
  "P_12_1_1_sum",
  gauge_lat = 54.686534,
  gauge_lon = -2.1862793
)

wr_check = rainfallqc$comparison_checks$check_exceedance_of_rainfall_world_record(
     grouped_df,
     "P_12_1_1_sum", 
     time_res="hourly"
)
wr_check["world_record_check"]$value_counts()
join <-  grouped_df$join(wr_check, on='time')
join$filter(pl$col("world_record_check") == 1)
join$filter(pl$col("world_record_check") == 4)
#############
# below doesn't work because it expect 1h or 15mins data not 30mins data like in our data
##########
rx1day_check = rainfallqc$comparison_checks$check_hourly_exceedance_etccdi_rx1day(
    grouped_df,
     "P_12_1_1_sum", 
    gauge_lat = 54.686534,
    gauge_lon = -2.1862793
)

rx1day_check["rx1day_check"]$value_counts()

#####################
#Time-series checks
#####################
py$cdd_check <- rainfallqc$timeseries_checks$check_dry_period_cdd(
  data = grouped_df,
  target_gauge_col = "P_12_1_1_sum",
  time_res = "hourly",
  gauge_lat = 54.686534,
  gauge_lon = -2.1862793
)

cdd_check <- py$cdd_check # R reticulate has a weird error and it should be done like this
cdd_check['dry_spell_flag']$value_counts()
cdd_check = grouped_df$join(cdd_check, on='time')
cdd_check$filter(pl$col("dry_spell_flag") == 4)

# get the plot

# get the dates 
# trying to automatise max and min dates but failing,....
# reticulate::py_install("pyarrow")
# pa <- import("pyarrow")
# start_date <- min_df$to_pandas()$iloc[0, 0]
# end_date   <- max_df$to_pandas()$iloc[0, 0]
start_date <- pl$date(2025L, 5L, 1L)
end_date <- pl$date(2025L, 6L, 30L)

filtered <- cdd_check$filter(
  (pl$col("time") > start_date) & 
  (pl$col("time") < end_date)
)

filtered_pd <- filtered$to_pandas()
plot(filtered_pd$time, filtered_pd$dry_spell_flag)

# left in QC13 - Daily accumulations from https://github.com/Thomasjkeel/RainfallQC-notebooks/blob/main/notebooks/demo/rainfallQC_demo.ipynb
#####################
#Comparison checks
#####################

```




