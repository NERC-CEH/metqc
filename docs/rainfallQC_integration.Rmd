---
title: "rainfallQC_integration"
output: html_document
---

# GitHub package
Public repository for the rainfallQC is here: https://github.com/NERC-CEH/RainfallQC
There is a notebook demo of how the package works here: https://github.com/Thomasjkeel/RainfallQC-notebooks/blob/main/notebooks/demo/rainfallQC_demo.ipynb

# Dependencies 

Each machine will have to have a series of requirements: 
* phyton 3.8 or later
* Dependencies for the rainfallQC package ()
* R with shiny and dependencies for metqc app.

# How it will work with a shiny app: 

- Use the R reticulate package
- Create a function to automatically set up the Python environment
- when ready to use: 
```{gneral_example r}


library(reticulate)

# Import the Python module
rainfallqc <- import("rainfallqc")

# Call a specific function, say `your_function_name`
result <- rainfallqc$your_function_name(arg1, arg2)

```

# Working example with the app 

The rainfall variables is named as `P_12_1_1`. 
The python package needs datect to be separated as dates and hours. 

```{app_example r}
# The app reads in df_era5_qry that is the ate range met data, we want to filter P_12_1_1

df_prec <- df_era5_qry %>%
  dplyr::select(P_12_1_1, DATECT)

# rainfall needs to be in mm and date/time in the same column
# it seems to do a nearest neighbour comparison but not sure where to get that data? we only have from one location


library(reticulate)
# Import the Python module
rainfallqc <- import("rainfallqc")
py_help(rainfallqc$gauge_checks) # a module with several functions

py_help(rainfallqc$gauge_checks$check_years_where_annual_mean_k_top_rows_are_zero)

#####################
#prepare data for python
#####################
# the dataset needs to be a polars dataframe 
#py_install("polars")
pl <- import("polars")
# 2. Convert R data.frame to Python dict
df_dict <- dict(
  DATECT = as.character(df_prec$DATECT),
  P_12_1_1 = df_prec$P_12_1_1
)

# 3. Create a Polars DataFrame
pl_df <- pl$DataFrame(df_dict)

# 4. Convert DATECT to datetime format in Polars
pl_df <- pl_df$with_columns(
  pl$col("DATECT")$str$to_datetime()
)

# 5. Use group_by_dynamic to group by 30m intervals otherwise the rainfallqc package fails
grouped_df <- pl_df$group_by_dynamic("DATECT", every="30m")$agg(
  list(
   pl$col("P_12_1_1")$sum()$alias("P_12_1_1_sum")
  )
)
# rename DATECT to time so the rainfallqc package works
grouped_df <- grouped_df$rename(dict(DATECT = "time"))

#####################
#Gauge checks
#####################

rainfallqc$gauge_checks$check_years_where_annual_mean_k_top_rows_are_zero(
    grouped_df,
    "P_12_1_1_sum",
    k = 1800
)

rainfallqc$gauge_checks$check_years_where_nth_percentile_is_zero(grouped_df, "P_12_1_1_sum", quantile=0.8) # if return list() No years or groups matched the condition where the 80th percentile of P_12_1_1_sum was zero.

rainfallqc$gauge_checks$check_breakpoints(grouped_df, "P_12_1_1_sum")

rainfallqc$gauge_checks$check_intermittency(grouped_df, "P_12_1_1_sum")

rainfallqc$gauge_checks$check_min_val_change(grouped_df, "P_12_1_1_sum", expected_min_val=0.1)

rainfallqc$gauge_checks$check_temporal_bias(grouped_df, "P_12_1_1_sum", time_granularity="weekday")

#####################
#Comparison checks
#####################

# all the data in teh app so far is from the same site: 
# as example lets say lat 54.686534 , lng -2.1862793
#add lat lng to the existing data.frame
grouped_df$lat <- 55.79259
grouped_df$lng <- -3.243

rainfallqc$comparison_checks$check_annual_exceedance_etccdi_prcptot(
  grouped_df,
  "P_12_1_1_sum",
  gauge_lat = 55.79259,
  gauge_lon = -3.243
)

rainfallqc$comparison_checks$check_annual_exceedance_etccdi_r99p(
   grouped_df,
  "P_12_1_1_sum",
  gauge_lat = 55.79259,
  gauge_lon = -3.243
)

wr_check = rainfallqc$comparison_checks$check_exceedance_of_rainfall_world_record(
     grouped_df,
     "P_12_1_1_sum", 
     time_res="hourly"
)
wr_check["world_record_check"]$value_counts()
join <-  grouped_df$join(wr_check, on='time')
join$filter(pl$col("world_record_check") == 1)
join$filter(pl$col("world_record_check") == 4)
#############
# below doesn't work because it expect 1h or 15mins data not 30mins data like in our data
##########
rx1day_check = rainfallqc$comparison_checks$check_hourly_exceedance_etccdi_rx1day(
    grouped_df,
     "P_12_1_1_sum", 
    gauge_lat = 54.686534,
    gauge_lon = -2.1862793
)

rx1day_check["rx1day_check"]$value_counts()

#####################
#Time-series checks
#####################
py$cdd_check <- rainfallqc$timeseries_checks$check_dry_period_cdd(
  data = grouped_df,
  target_gauge_col = "P_12_1_1_sum",
  time_res = "hourly",
  gauge_lat = 54.686534,
  gauge_lon = -2.1862793
)

cdd_check <- py$cdd_check # R reticulate has a weird error and it should be done like this
cdd_check['dry_spell_flag']$value_counts()
cdd_check = grouped_df$join(cdd_check, on='time')
cdd_check$filter(pl$col("dry_spell_flag") == 4)

# get the plot

# get the dates 
# trying to automatise max and min dates but failing,....
# reticulate::py_install("pyarrow")
# pa <- import("pyarrow")
# start_date <- min_df$to_pandas()$iloc[0, 0]
# end_date   <- max_df$to_pandas()$iloc[0, 0]
start_date <- pl$date(2025L, 5L, 1L)
end_date <- pl$date(2025L, 6L, 30L)

filtered <- cdd_check$filter(
  (pl$col("time") > start_date) & 
  (pl$col("time") < end_date)
)

filtered_pd <- filtered$to_pandas()
plot(filtered_pd$time, filtered_pd$dry_spell_flag)

#############
# QC13 - below doesn't work because it expect 1h or 15mins data not 30mins data like in our data
##########
daily_accumulation <- rainfallqc$timeseries_checks$check_daily_accumulations(
  grouped_df,
  target_gauge_col = "P_12_1_1_sum",
  gauge_lat = 54.686534,
  gauge_lon = -2.1862793,
  wet_day_threshold = 1.0,
  accumulation_multiplying_factor = 2.0
)
daily_accumulation[["daily_accumulation"]]$value_counts()
joined <- grouped_df$join(daily_accumulation, on="time")
daily_accumulation$filter(
  pl$col("daily_accumulation") == 1.0
)

#then it plots it but because it doesn't work,...
# Run monthly accumulations
#############
# QC14 - below doesn't work because it expect 1h, 15m or 1d data not 30mins data like in our data
##########
monthly_accumulations <- rainfallqc$timeseries_checks$check_monthly_accumulations(
  grouped_df,
  "P_12_1_1_sum", # I am not sure this is the same as the gauge column? 
  gauge_lat = 54.686534,
  gauge_lon = -2.1862793
)

# Join monthly_accumulations back to gdsr_data on "time"
monthly_accumulations <- grouped_df$join(
  monthly_accumulations,
  on = "time"
)

# Filter where monthly_accumulation == 2
filtered <- monthly_accumulations$filter(
  pl$col("monthly_accumulation") == 2
)

# QC15 - below doesn't work because it expect 1h, 15m or 1d data not 30mins data like in our data
#Flag 1: 2 or more repeated above extreme rain
#Flag 3: streaks of 12 or more greater than data resolution
#Flag 4: streaks of 24 or more greater than 0
#Flag 5: Periods of 0 as multiples of 24

# unsure the TARGET_GAUGE_COL is the same as the rain column?
streaks <- rainfallqc$timeseries_checks$check_streaks(
  grouped_df,
  target_gauge_col = "P_12_1_1_sum",
  gauge_lat = 54.686534,   # or gdsr_metadata[["latitude"]]
  gauge_lon = -2.1862793,  # or gdsr_metadata[["longitude"]]
  data_resolution = "hourly"  # or gdsr_metadata[["resolution"]]
)

# Count values of streak_flag1
vc <- streaks[["streak_flag1"]]$value_counts()
print(vc)

#####################
#Neighborhood checks
#####################
#QC16 Daily neighbours (wet) _ question it says there is Q16 to 25 but I only can see 16. 

# neighbour data - we don't have this data in the app ??? is it package automatic? dont' get it 
neighbour_cols <- gdsr_network_data$columns$to_list()
neighbour_cols <- neighbour_cols[neighbour_cols != target_col]


wet_daily_check <- rainfallqc$neighbourhood_checks$check_wet_neighbours(
  grouped_df,
  target_gauge_col      = "P_12_1_1_sum",
  neighbouring_gauge_cols = neighbour_cols,
  time_res              = "1h",
  wet_threshold         = 1.0,
  min_n_neighbours      = 5,
  n_neighbours_ignored  = 0
)

# Value counts
vc <- wet_daily_check[["wet_spell_flag_hourly"]]$value_counts()
print(vc)

```




